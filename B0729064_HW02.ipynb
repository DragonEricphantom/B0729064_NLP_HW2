{"nbformat":4,"nbformat_minor":2,"metadata":{"colab":{"name":"B0729064_HW02.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3.7.7 64-bit"},"language_info":{"name":"python","version":"3.7.7","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"interpreter":{"hash":"9164a3399a70d355c381b62813f30880ed90ca5a6f321bf0d85375640bda7ee5"}},"cells":[{"cell_type":"code","execution_count":null,"source":["import multiprocessing\r\n","from multiprocessing import Process, Queue\r\n","\r\n","import time\r\n","from lxml import etree\r\n","import requests\r\n","from bs4 import BeautifulSoup\r\n","\r\n","#url = 'https://movies.yahoo.com.tw/moviegenre_result.html?genre_id=1'\r\n","url = 'https://movies.yahoo.com.tw/movie_thisweek.html'\r\n","infos = []\r\n","def check_req_url(url): #測試請求網址是否請求成功\r\n","    r = requests.get(url) #請求網址\r\n","    #print(resp.status_code) #錯誤時404,成功時200\r\n","    if r.status_code != 200:  #如果請求失敗\r\n","        print('Invalid url:', r.url) #印出請求失敗的網址\r\n","        return \"fail\" #回傳失敗提示訊息\r\n","    else:\r\n","        return r.text #回傳請求成功的html文字\r\n","\r\n","def get_week_new_movies(webpage): #抓取電影資訊\r\n","  soup = BeautifulSoup(webpage) #網頁解析\r\n","  exist = soup.find_all('div', id = 'content_l')\r\n","  if exist:\r\n","    for d in soup.find_all('div', id=\"content_l\"):\r\n","        info = {}\r\n","        info['中文名稱'] = d.find('div', class_='movie_intro_info_r').find('h1').text.strip()\r\n","        info['英文名稱'] = d.find('div', class_='movie_intro_info_r').find('h3').text.strip()\r\n","        info['上映日期'] = d.find('span').text.strip()\r\n","        info['劇情介紹'] = d.find('div', class_='gray_infobox storeinfo').find('div', class_='gray_infobox_inner').find('span',id='story').text.strip()\r\n","        # info['連接介紹'] = d.find('div', class_='release_movie_name').find('a', class_='gabtn').get('href')\r\n","        # net = d.find('div', class_='release_movie_name').find('a', class_='gabtn').get('href')\r\n","        level_name = d.find('div', class_='movie_intro_info_r').find_all('div',class_='level_name')\r\n","        str =''\r\n","        for level in level_name:\r\n","          str += level.a.text.strip()+',' \r\n","        info['Label'] = str   \r\n","        infos.append(info) \r\n","    return infos\r\n","  else:\r\n","    return 0\r\n","\r\n","if __name__ == '__main__':\r\n","  headers = {\r\n","      'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/92.0.4515.131 Safari/537.36'\r\n","  }\r\n","# url = 'https://movies.yahoo.com.tw/movieinfo_main/9'\r\n","# check_req_url(url)\r\n","  for i in range(1,10000):\r\n","    print(i)\r\n","    url = 'https://movies.yahoo.com.tw/movieinfo_main/%d'%(i)+''\r\n","    r = requests.get(url, headers=headers)\r\n","    soup = BeautifulSoup(r.text) #網頁解析\r\n","    #exist = soup.find_all('div', id = 'content_l')\r\n","   # print(soup.find_all('div', class_ = 'movie_intro_info_r').find('h1').text.strip())\r\n","    if soup.find_all('div', class_='movie_intro_info_r'):\r\n","      infos = get_week_new_movies(r.text)\r\n","    else:\r\n","      print(\"NON\")\r\n","      continue\r\n","  import pandas as pd\r\n","\r\n","  df = pd.DataFrame(infos)\r\n","  df.to_csv('movies.csv', encoding='utf_8_sig')     \r\n","      \r\n","  df    \r\n","    \r\n","\r\n","  # url = 'https://movies.yahoo.com.tw/movieinfo_main/1'\r\n","  # r = requests.get(url, headers=headers)\r\n","  # infos = get_week_new_movies(r.text)\r\n","\r\n","  # webpage = check_req_url(url)\r\n","  # if webpage:\r\n","  #   infos = get_week_new_movies(webpage)\r\n","  # for info in infos:\r\n","  #   print(info)\r\n"],"outputs":[{"output_type":"stream","name":"stdout","text":["1\n","2\n","3\n","4\n","5\n","6\n","7\n","8\n","9\n","NON\n","10\n","11\n","12\n","13\n","14\n","15\n","16\n","NON\n","17\n","NON\n","18\n","19\n","20\n","NON\n","21\n","NON\n","22\n","23\n","24\n","25\n","26\n","27\n","28\n","29\n","30\n","31\n","32\n","33\n","34\n","35\n","36\n","37\n","38\n","39\n","40\n","41\n","42\n","43\n","44\n","45\n","46\n","47\n","48\n","49\n","NON\n","50\n","51\n","NON\n","52\n","53\n","54\n","55\n","56\n","57\n","58\n","59\n","60\n","61\n","62\n","63\n","64\n","65\n","66\n","NON\n","67\n","68\n","NON\n","69\n","70\n","71\n","NON\n","72\n","73\n","74\n","75\n","76\n","77\n","78\n","79\n","80\n","81\n","82\n","83\n","84\n","85\n","86\n","87\n","88\n","89\n","90\n","91\n","92\n","93\n","94\n","95\n","96\n","97\n","98\n","99\n","100\n","101\n","102\n","103\n","104\n","105\n","106\n","107\n","108\n","109\n","110\n","111\n","112\n","113\n","114\n","115\n","116\n","117\n","118\n","119\n","120\n","121\n","122\n","123\n","124\n","125\n","126\n","127\n","128\n","129\n","130\n","131\n","132\n","133\n","134\n","135\n","136\n","137\n","138\n","139\n","140\n","141\n","142\n","143\n","144\n","145\n","146\n","147\n","148\n","149\n","150\n","151\n","152\n","153\n","154\n","155\n","156\n","157\n","158\n","NON\n","159\n","160\n","161\n","NON\n","162\n","163\n","NON\n","164\n","NON\n","165\n","166\n","NON\n","167\n","NON\n","168\n","NON\n","169\n","NON\n","170\n","NON\n","171\n","172\n","173\n","174\n","175\n","176\n","177\n","178\n","179\n","180\n","181\n","182\n","183\n","184\n","NON\n","185\n","NON\n","186\n","NON\n","187\n","NON\n","188\n","189\n","NON\n","190\n","191\n","192\n","193\n","NON\n","194\n","195\n","196\n","197\n","198\n","199\n","200\n","201\n","202\n","203\n","204\n","205\n","206\n","207\n","208\n","209\n","210\n","211\n","212\n","213\n","NON\n","214\n","NON\n","215\n","NON\n","216\n","NON\n","217\n","218\n","NON\n","219\n"]}],"metadata":{"id":"lkVXh8P8VmzA","colab":{"base_uri":"https://localhost:8080/"},"outputId":"8b9d1139-3cd9-4cfc-f818-56e93244f7d3"}}]}